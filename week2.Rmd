---
title: "BMS353 Bioinformatics for Biomedical Science - Week 2"
author: "Module Coordinator Mark Dunning"
output: 
  html_notebook: 
    toc: yes
    toc_float: yes
    css: stylesheets/styles.css
editor_options: 
  chunk_output_type: inline
---

<img src="images/logo-sm.png" style="position:absolute;top:40px;right:10px;" width="200" />


# Introduction

In this tutorial we will get our first look at how to analyse high-throughput biological data in R. The majority of the course will discuss RNA-seq data for gene expression, but in this session we will consider data from an older technology; *microarrays*.

Although considered outdated by many, the prevalence of microarrays in public repositories make them a valuable resource.

You will need to have installed the following packages before starting:-

```{r eval=FALSE}
install.packages("BiocManager")
BiocManager::install("GEOquery")
BiocManager::install("limma")
BiocManager::install("genefilter")

```


# Importing the data

The data from this experiment comprises nine paired tumor/normal colon tissues on Illumina HT12\_v3 gene expression Beadchips. We will assume that you already know the accession number (GSE....) for the dataset that you want to download. This should usually be declared as part of the manuscript, and journals are becoming increasingly strict about making sure that data accompanying a publication are available through a suitable repository. The Gene Expression Omnibus (GEO) is one such resource for biological data.


```{r echo=FALSE,message=FALSE}
library(GEOquery)
library(limma)
```

<div class="information">
These data were generated using Illumina microarrays, but the procedure should be highly similar for other manufacturers. e.g. Affymetrix.
</div>

The [landing page](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE33126) has a link to download the *series matrix*. We can download this within R if we wish using the function `download.file`.

The `getGEO` function from `GEOquery` can then import these data into R. The data are a bit more complicated that the spreadsheets we have dealt with so far, so we have to use a specialised package rather than `read_csv` etc.

```{r cache=TRUE, message=FALSE}
library(GEOquery)
## can change the url to be the dataset that you want.

url <- "https://ftp.ncbi.nlm.nih.gov/geo/series/GSE33nnn/GSE33126/matrix/GSE33126_series_matrix.txt.gz"

download.file(url, destfile = "GSE33126_series_matrix.txt.gz")

gse <- getGEO(filename = "GSE33126_series_matrix.txt.gz")

```

## Data Representation

We usually print the contents of an object to the screen by running a line of code corresponding to the name of the object. However, the `gse` object works a bit differently.

```{r}
gse

```

The microarray technology employed has given us a gene expression measurement for each probe (/ gene) and biological sample. This is a data matrix with one row for each probe (/gene ) and one column for each sample. However, this is not sufficient information for the analysis. We also need to know

- Which biological groups each sample belongs to, and any other relevant information.
    + e.g. tumour/normal status, age, gender, batch
- Which gene each probe is measuring
    + what is the common name for the gene
    + what are it's genomic coordinates
    + what pathways does it belong to.
    
These different sources of data are all available in the `gse` object and are accessed using different functions.

```{r eval=FALSE}
pData(gse) ## print the sample information
fData(gse) ## print the gene annotation
exprs(gse) ## print the expression data
```


# Quality Asssessment and Normalisation (if required)

For visualisation and statistical analysis, we will inspect the data to discover what *scale* the data are presented in and check if they have been normalised. Most methods will work better if the data are on a log$_2$ scale; typically in the range of 0 to 16. 

The `exprs` function can retrieve the expression values as a data frame; with one column per-sample and one row per-gene.

The `summary` function can then be used to print the distributions.

```{r}
## exprs get the expression levels as a data frame and get the distribution
summary(exprs(gse))
```

From this output we clearly see that the values go beyond 16, so we will need to perform a $log_2$ transformation. We can save our normalised values as a new object so we can use them later. A `boxplot` can also be generated to see if the data have been normalised. Each "box" on the plot shows the distribution of gene expression measurements for a particular sample. If so, the distributions of each sample should be highly similar.

```{r}
normData <- log2(exprs(gse))
boxplot(normData,outline=FALSE)
```

<div class="information">
An easy to follow demonstration of the most-popular normalisation method (quantile normalisation) can be found here
[https://youtu.be/ecjN6Xpv6SE](https://youtu.be/ecjN6Xpv6SE)
</div>

## Inspect the clinical variables

Data submitted to GEO contain sample labels assigned by the experimenters, and some information about the processing protocol. All these data can be extracted by the `pData` function. 

**For your own data, you will have to decide which columns will be useful in the analysis**. This will include the column giving the main comparison(s) of interest and any potential confounding factors. In this particular dataset it looks like `source_name_ch1` and `characteristics_ch1.1`.

We can use the `select` function from `dplyr` to display just these columns of interest. At this stage it will also be useful to rename the columns to something more convenient using the `rename` function.

```{r}
library(dplyr)
sampleInfo <- pData(gse)
sampleInfo

## source_name_ch1 and characteristics_ch1.1 seem to contain factors we might need for the analysis. Let's pick just those columns

sampleInfo <- select(sampleInfo, source_name_ch1,characteristics_ch1.1)

## Optionally, rename to more convenient column names
sampleInfo <- rename(sampleInfo,group = source_name_ch1, patient=characteristics_ch1.1)
```

Our sample information is therefore:-

```{r}
sampleInfo
```


## Exporting the data

We can export the expression data to a `csv` for inspection in Excel using the `write_csv` function from `readr`. The expression values themselves will probably not be very useful as they will be named according to manufacturer ID rather than gene name (for example). We can create a matrix by joining the expression matrix with the feature annotation.

```{r}
library(readr)
full_output <- cbind(fData(gse),normData)
write_csv(full_output, path="gse_full_output.csv")
```

The annotation from GEO might contain lots of columns that we are not particularly interested in. To keep the data tidier we can use the `select` function to only print particular columns in the output.

```{r}
features <- fData(gse)
View(features)
### Look at the features data frame and decide the names of the columns you want to keep
features <- select(features,Symbol,Entrez_Gene_ID,Chromosome,Cytoband)
full_output <- cbind(features,exprs(gse))
write_csv(full_output, path="gse_full_output.csv")

```


# Statistical Testing

By far the most-popular package for performing differential expression is `limma`. The user-guide is extensive and covers the theory behind the analysis and many use-cases (Chapters 9 and 17 for single-channel data such as Illumina and Affymetrix)

https://bioconductor.org/packages/release/bioc/vignettes/limma/inst/doc/usersguide.pdf

To illustrate the process of statistical testing, we will use a simple t-test, **which is not recommended in practice**.

To motivate the problem we are trying to solve, we can look at the distribution of expression values for a single gene using a boxplot. We use the base R convention for subsettting a data frame; which is to use square brackets (`[]`) with a row and column index to indicate the rows and columns of data we want to retrieve. If the column index is omitted, it means show all columns. 

The `~` notation is used to specify the sample groups we want to compare between. Although `ggplot` is recommended for publication quality graphics, it is sometimes easier to use the *base* equivalent.

```{r}
fac <- as.factor(sampleInfo$group)
boxplot(normData[1,]~fac)
```
It would appear that the expression level is higher in normal samples compared to tumor. We can perform a statistical test to assess the difference. If the data can be assumed to be *normally-distributed* and *independent* then a two-sample t-test can be employed yielding a p-value and measure of the difference between the sample groups.

```{r}
t.test(normData[1,]~fac,var.equal=TRUE)
```

It would be tedious to test each gene individually. Fortunately the `genefilter` package includes a convenient `rowttests` function that will rapidly test each gene. The output shows the test statistic, difference of means (dm) and p-value for each gene.


```{r}
library(genefilter)
fac <- as.factor(sampleInfo$group)
test_results <- rowttests(normData, fac)
head(test_results)
```
However, you might notice from the output that the names of each probe doesn't have a column heading associated with it. We have to make a small change to the output so that `dplyr` functions can be used.

```{r}
test_results <- tibble::rownames_to_column(test_results,"ID")
```

## Multiple testing correction

Unfortunately, generating the p-values is not the end of the story. Since genome-wide technologies permit us to interrogate many thousands of genes simultaneously, we are likely to obtain many *false-positive* findings. The concept of false positives is nicely summarised in this graphic:-

![](https://raw.githubusercontent.com/sheffield-bioinformatics-core/IntroductionToStats/master/images/EffectSizeFAQs.PNG)

[original source for picture](https://effectsizefaq.com/2010/05/31/i-always-get-confused-about-type-i-and-ii-errors-can-you-show-me-something-to-help-me-remember-the-difference/)

Rather than reporting the *raw* p-values it is highly-recommended to adjust for the fact that we performed many thousands of tests. The most popular method is the Benjamini-Hochberg (BH) as described in the following video. 


<div class="information">

StatQuest video on multiple testing

[https://youtu.be/K8LQSvtjcEo](https://youtu.be/K8LQSvtjcEo)
</div>

The `p.adjust` function is a general-purpose function for adjusting p-values.

```{r}
?p.adjust
```




### Exercise

<div class="exercise">
- How would you re-arrange the rows of`test_results` according to p-value? Which gene has the lowest p-value?
- Add a new column `padj` to `test_results`containing p-values adjusted with the BH method. Consult the R introductory course or `dplyr` cheatsheet to recall how to add columns to a data frame.
    + How many genes have an *adjusted* p-value less than 0.05?
</div>

# Further processing and visualisation of DE results

At the moment our results are not particularly easy to navigate as the only information to identify each gene is the identifier that the microarray manufacturer has assigned. Fortunately, the GEO entry contains extensive annotation that we can add. The annotation data can be retrieved with the `fData` function and we restrict to columns we are interested in using `select`.

**For your own data, you will have to choose the columns that are of interest to you. You probably won't have the same column headings used here**.

Once an annotation data frame has been created, it merged to our results using the `left_join` function.

```{r}
anno <- fData(gse)
anno <- select(anno,Symbol,Entrez_Gene_ID,Chromosome,Cytoband)
anno <- tibble::rownames_to_column(anno,"ID")
test_results <- left_join(test_results,anno)
```





The "*Volcano Plot*" function is a common way of visualising the results of a DE analysis. The $x$ axis shows the log-fold change and the $y$ axis is some measure of statistical significance, which in this case is the log-odds, or "B" statistic. A characteristic "volcano" shape should be seen.


The basic plot is created as follows:-

```{r}
## Make sure you have ggplot2 loaded
library(ggplot2)
ggplot(test_results,aes(x = dm, y=-log10(p.value))) + geom_point()
```

The flexibility of `ggplot2` allows us to automatically label points on the plot that might be of interest. For example, genes that meet a particular p-value and log fold-change cut-off. With the code below the values of `p_cutoff` and `fc_cutoff` can be changed as desired.

```{r}
## change according to your needs
p_cutoff <- 0.05
fc_cutoff <- 1

test_results %>% 
  mutate(Significant = p.value < p_cutoff, abs(dm) > fc_cutoff ) %>% 
  ggplot(aes(x = dm, y = -log10(p.value), col=Significant)) + geom_point()
```


# Interpretation of Results

The `filter` function from `dplyr` gives a convenient way to interrogate the table of results.

```{r}
## Get the results for particular gene of interest
filter(test_results, Symbol == "SMOX")
## Get results for genes with TP53 in the name
filter(test_results, grepl("TP53", Symbol))
## Get results for one chromosome
filter(test_results, Chromosome==20)
```

We can also filter according to p-value (adjusted) and fold-change cut-offs

```{r}
p_cutoff <- 0.05
fc_cutoff <- 1

filter(test_results, p.value < 0.05, abs(dm) > 1)
```

These results can be exported with the `write_csv` function.

```{r}
library(readr)
filter(test_results, p.value < 0.05, abs(dm) > 1) %>%
  write_csv(path="filtered_de_results.csv")
```


# Exercise for next time

<div class="exercise">

- Create a new RStudio project and write a markdown file to document the analysis of the GEO dataset `GSE33126`
- Include the key stages of the analysis in your report
  + downloading the data
  + quality assessment
  + log$_2$ transformation
  + statistical testing
  + export the results
  
</div>

# Disclaimer

Remember that the t-test is not 

[Microarray Analysis with limma](https://youtu.be/ZRet1oeGiUU)



## Optional (Clustering)

## Sample clustering

Unsupervised analysis is a good way to get an understanding of the sources of variation in the data. It can also identify potential outlier samples.

The function `cor` can calculate the correlation (on scale between -1 and 1) in a pairwise fashion between all samples. A pair of samples with correlation close to 1 is highly similar. The correlation values are then used in an *un-supervised* clustering


Among the many options for creating heatmaps in R, the `pheatmap` library is one of the more popular ones. The only argument it requires is a matrix of numerical values (such as the correlation matrix).

```{r}
library(pheatmap)
## argument use="c" stops an error if there are any missing data points

corMatrix <- cor(normData,use="c")
pheatmap(corMatrix)                
```

We can incorporate sample information onto the plot to try and understand the clustering. We have already created such a data frame previously (`sampleInfo`). However, we need to take care that the rownames of these data match the columns of the correlation matrix.

```{r}
## Print the rownames of the sample information and check it matches the correlation matrix
rownames(sampleInfo)
colnames(corMatrix)

## If not, force the rownames to match the columns

rownames(sampleInfo) <- colnames(corMatrix)
pheatmap(corMatrix,
         annotation_col=sampleInfo)    
```

Here we see that the main separation is due to normal vs tumours; as we hope. Inspecting the correlation heatmap may reveal other issues in the data such as outlier samples and batch effects.

Another approach to visualise the relationships between samples is Principal Components Analysis (PCA), which we will see later in the course.